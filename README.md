# tk-llm

A Python GUI launcher for local LLM models using llama.cpp.

## Features
- Model configurations and formatted input
- Real-time output streaming in GUI or terminal mode
- Adjustable generation parameters (temperature, top-k, top-p, ngl, max tokens)
- Output management functionality
- Support for Harmony Response Format and simple prompting

## Requirements
- Python 3.x with tkinter
- llama-cli executable from llama.cpp
- Compatible GGUF model files

## Usage
```bash
python prompt.py
```

Place model files in the same directory as the script, under llama-**/.
